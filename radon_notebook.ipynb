{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;18m__file__\u001b[39m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.path.realpath(__file__)))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "def load_SMHI_data(file_name, path):\n",
    "    for i in range(6, 12):\n",
    "        try:\n",
    "            df = pd.read_csv(path+file_name, header=i, sep=\";\")\n",
    "        except:\n",
    "            continue\n",
    "        if df.columns[0] != \"Datum\":\n",
    "            continue\n",
    "        else:\n",
    "            print(file_name, df.shape)\n",
    "            return df\n",
    "    raise OverflowError(\"Number of iterations exceeded\")\n",
    "    \n",
    "def retrieve_datetime(df: pd.DataFrame) -> pd.Series:\n",
    "    return pd.to_datetime(df[\"Datum\"] + \" \" + df[\"Tid (UTC)\"])\n",
    "    \n",
    "# Läs in datan från SMHI\n",
    "dataframes = [load_SMHI_data(file, \"data_24-11-29/\") for file in os.listdir(\"data_24-11-29\")]\n",
    "\n",
    "# Läs in radon-datan\n",
    "df_main = pd.read_csv(\"radon_2024-11-30.csv\", sep=\",\", header=5)\n",
    "\n",
    "# Formatera \n",
    "df_main.columns = [\"Datum\", \"Radon\"]\n",
    "df_main[\"Datum\"] = pd.to_datetime(df_main[\"Datum\"], format = \"%d/%m/%Y %H:%M\").dt.round(\"h\")\n",
    "\n",
    "parameters = ['Lufttemperatur',  'Vindriktning', 'Vindhastighet', 'Rådande väder', \n",
    "              'Lufttryck reducerat havsytans nivå',  'Nederbördsmängd', 'Global Irradians (svenska stationer)',\n",
    "              'Solskenstid']\n",
    "\n",
    "df_main.index = pd.DatetimeIndex(pd.to_datetime(df_main[\"Datum\"]))\n",
    "\n",
    "\n",
    "idx = pd.date_range(df_main.index[0], df_main.index[-1], freq=\"h\")\n",
    "\n",
    "for df in dataframes:\n",
    "    df.index = pd.DatetimeIndex(retrieve_datetime(df))\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    for par in parameters:\n",
    "        if par in df.columns:\n",
    "            df_main.insert(df_main.shape[1], par, df[par])\n",
    "\n",
    "# for par in parameters:\n",
    "#     df_main.plot(y=\"Radon\", x=par, kind=\"scatter\")\n",
    "\n",
    "df_main.describe()\n",
    "\n",
    "df_main = df_main.iloc[:,1:]\n",
    "\n",
    "df_train = df_main.dropna().sample(frac=0.8, random_state=0)\n",
    "df_test = df_main.dropna().drop(df_train.index)\n",
    "\n",
    "train_labels = df_train.pop(\"Radon\")\n",
    "test_labels = df_test.pop(\"Radon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 15:35:03.626841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      6\u001b[0m normalizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mNormalization(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m normalizer\u001b[38;5;241m.\u001b[39madapt(np\u001b[38;5;241m.\u001b[39marray(df_train))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(normalizer\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_and_compile_model\u001b[39m(norm):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "normalizer.adapt(np.array(df_train))\n",
    "print(normalizer.mean.numpy())\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "  return model\n",
    "\n",
    "\n",
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    df_train,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='validation_loss')\n",
    "  plt.ylim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  \n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.evaluate(df_test, test_labels, verbose=0)\n",
    "\n",
    "x = tf.linspace(1, 20, 420)\n",
    "y = dnn_model.predict(df_test)\n",
    "test_result = dnn_model.evaluate(df_test, test_labels)\n",
    "print(test_result)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, test_labels)\n",
    "plt.ylabel(\"Radon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
